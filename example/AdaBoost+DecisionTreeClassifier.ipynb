{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "from learner import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ensemble import *\n",
    "from metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 西瓜数据集\n",
    "data=pd.read_csv(\"./dataset/watermelon3_0_Ch.csv\")\n",
    "\n",
    "data_X=data.iloc[:,1:-1].values\n",
    "data_Y=data.iloc[:,-1].values\n",
    "\n",
    "adaboost=AdaBoost(10,DecisionTreeClassifier,4,True)\n",
    "adaboost.fit(data_X,data_Y)\n",
    "\n",
    "y_predict=adaboost.predictBatch(data_X)\n",
    "print(y_predict)\n",
    "\n",
    "# 计算accuracy\n",
    "print(\"Accuracy:\",accuracy_score(data_Y,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 含有缺失值的西瓜数据集\n",
    "data=pd.read_csv(\"./dataset/watermelon2_0a_Ch.csv\")\n",
    "\n",
    "data=data.fillna(pd.NA)\n",
    "data_X=data.iloc[:,1:-1].values\n",
    "data_Y=data.iloc[:,-1].values\n",
    "\n",
    "# 缺失值处理\n",
    "for i in range(data_X.shape[1]):\n",
    "    column=data_X[:,i]\n",
    "    \n",
    "    na_list=[]\n",
    "    not_na_list=[]\n",
    "    TYPE=\"\"\n",
    "    for j in range(len(column)):\n",
    "        if pd.isna(column[j]):\n",
    "            na_list.append(j)\n",
    "            continue\n",
    "        else:\n",
    "            not_na_list.append(column[j])\n",
    "        if TYPE==\"\":\n",
    "            if np.issubdtype(type(column[j]),np.number):\n",
    "                TYPE=\"Continuous\"\n",
    "            else:\n",
    "                TYPE=\"Discrete\"\n",
    "    if TYPE==\"Continuous\":\n",
    "        for j in na_list:\n",
    "            column[j]=np.mean(not_na_list)\n",
    "    else:\n",
    "        count={}\n",
    "        for i in not_na_list:\n",
    "            if count.get(i)==None:\n",
    "                count[i]=1\n",
    "            else:\n",
    "                count[i]+=1\n",
    "        most=sorted(count.items(),key=lambda x :x[1],reverse=True)[0][0]\n",
    "        for j in na_list:\n",
    "            column[j]=most\n",
    "\n",
    "\n",
    "adaboost=AdaBoost(5,DecisionTreeClassifier,4,True)\n",
    "adaboost.fit(data_X,data_Y)\n",
    "y_predict=adaboost.predictBatch(data_X)\n",
    "print(y_predict)\n",
    "\n",
    "# 计算accuracy\n",
    "print(\"Accuracy:\",accuracy_score(data_Y,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 糖尿病数据集\n",
    "# 中等能力的学习器（深度限制为8的决策树）可以看到Err的下降趋势\n",
    "# 虽然能靠boost使train_set上达到100%的预测，但是也容易过拟合，在test_set上表现并不比单个学习器表现好\n",
    "\n",
    "data=pd.read_csv(\"./dataset/pima-indians-diabetes.csv\")\n",
    "print(data.info())\n",
    "\n",
    "data_X=data.iloc[:,0:-1].values\n",
    "data_Y=data.iloc[:,-1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.2)\n",
    "\n",
    "adaboost=AdaBoost(20,DecisionTreeClassifier,8,True)\n",
    "adaboost.fit(x_train,y_train)\n",
    "\n",
    "print(\"Depth:\",[boosted_learner.learner.depth for boosted_learner in adaboost.boosted_learner_list])\n",
    "\n",
    "# 预测train_set\n",
    "y_predict=adaboost.predictBatch(x_train)\n",
    "print(\"Train_set Accuracy:\",accuracy_score(y_train,y_predict))\n",
    "\n",
    "# 预测test_set\n",
    "y_predict=adaboost.predictBatch(x_test)\n",
    "print(\"Test_set Accuracy:\",accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 鸢尾花数据集\n",
    "# boost的效果很明显\n",
    "# 可以看到boost确实能靠多个弱学习器（深度限制为2的决策树），实现总体性能的增强\n",
    "# 三个臭皮匠比一个臭皮匠强\n",
    "\n",
    "data=pd.read_csv(\"./dataset/iris.csv\")\n",
    "print(data.info())\n",
    "\n",
    "data_X=data.iloc[:,:-1].values\n",
    "data_Y=data.iloc[:,-1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.2)\n",
    "\n",
    "adaboost=AdaBoost(10,DecisionTreeClassifier,2,True,stop_in_advance=True)\n",
    "adaboost.fit(x_train,y_train)\n",
    "\n",
    "# 预测train_set\n",
    "y_predict=adaboost.predictBatch(x_train)\n",
    "print(\"Train_set Accuracy:\",accuracy_score(y_train,y_predict))\n",
    "\n",
    "# 预测test_set\n",
    "y_predict=adaboost.predictBatch(x_test)\n",
    "print(\"Test_set Accuracy:\",accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 泰坦尼克部分数据集太难了\n",
    "# boost的效果不好！\n",
    "\n",
    "data=pd.read_csv(\"./dataset/titanic.csv\")\n",
    "\n",
    "orig = data['Pclass'].unique().tolist()\n",
    "baked = [ chr(i) for i in range(65,65+len(orig))]\n",
    "data['Pclass']=data['Pclass'].apply(lambda x: baked[orig.index(x)])\n",
    "\n",
    "data[\"Age\"]=data[\"Age\"].fillna(data[\"Age\"].median())\n",
    "\n",
    "orig = data['SibSp'].unique().tolist()\n",
    "baked = [ chr(i) for i in range(65,65+len(orig))]\n",
    "data['SibSp']=data['SibSp'].apply(lambda x: baked[orig.index(x)])\n",
    "\n",
    "orig = data['Parch'].unique().tolist()\n",
    "baked = [ chr(i) for i in range(65,65+len(orig))]\n",
    "data['Parch']=data['Parch'].apply(lambda x: baked[orig.index(x)])\n",
    "\n",
    "data['Embarked']=data['Embarked'].fillna(\"S\")\n",
    "print(data.info())\n",
    "\n",
    "data_X=data.iloc[:,2:-1].values\n",
    "data_Y=data.iloc[:,1].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.2)\n",
    "\n",
    "adaboost=AdaBoost(10,DecisionTreeClassifier,20,True)\n",
    "adaboost.fit(x_train,y_train)\n",
    "\n",
    "# 预测train_set\n",
    "y_predict=adaboost.predictBatch(x_train)\n",
    "print(\"Train_set Accuracy:\",accuracy_score(y_train,y_predict))\n",
    "\n",
    "# 预测test_set\n",
    "y_predict=adaboost.predictBatch(x_test)\n",
    "print(\"Test_set Accuracy:\",accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boost的效果很明显\n",
    "# 可以看到boost确实能靠多个弱学习器（深度限制为2的决策树），实现总体性能的增强\n",
    "# 三个臭皮匠比一个臭皮匠强\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data=load_breast_cancer()\n",
    "data_X=data.data\n",
    "data_Y=data.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.2)\n",
    "\n",
    "adaboost=AdaBoost(10,DecisionTreeClassifier,2,True,stop_in_advance=True)\n",
    "adaboost.fit(x_train,y_train)\n",
    "\n",
    "# 预测train_set\n",
    "y_predict=adaboost.predictBatch(x_train)\n",
    "print(\"Train_set Accuracy:\",accuracy_score(y_train,y_predict))\n",
    "\n",
    "# 预测test_set\n",
    "y_predict=adaboost.predictBatch(x_test)\n",
    "accuracy=y_predict[y_predict==y_test].shape[0] / y_test.shape[0]\n",
    "print(\"Test_set Accuracy:\",accuracy_score(y_test,y_predict))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c207cf98bc84bffc44ccf9494458b90a53a5c17a03e11155797855f32f2c5f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
